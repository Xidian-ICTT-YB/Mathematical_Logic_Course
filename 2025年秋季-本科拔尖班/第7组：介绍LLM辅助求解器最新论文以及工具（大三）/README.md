# The introduction and use of the symbolic execution engine KLEE

## 小组成员

| 学号        | 姓名   |
| ----------- | ------ |
| 23009200717 | 程彦彰 |
| 23009290035 | 王云峰 |
| 23009201243 | 马梓灿 |
| 23009290071 | 常宇轩 |

## 工作简介

- 优化建模背景与挑战：结合生产排程、手术排班等案例，梳理优化建模的基本流程，重点分析“把大白话需求翻译成数学模型”“选择合适求解工具”“在算对基础上进一步算快”这三大核心壁垒。
- OptiMUS-0.3 流程解析：系统介绍从自然语言问题输入、参数与 Clause 提取，到数学形式化建模、代码自动生成与组装、迭代调试再到最终求解与结果输出的完整闭环，实现“一句需求到可执行求解代码”的自动化链路。
- 支撑模块说明：拆解状态管理、误差修正模块和效率优化模块三大核心组件，阐释如何通过 JSON 状态维护全程信息、利用反射式提示与自评打分缓解 LLM 幻觉，并借助结构检测与高级编码策略提升大规模问题的求解效率。
- 应用与前沿展望：基于 OptiMUS 在线 Demo 等实践展示 LLM 辅助求解器在真实优化建模任务中的效果，讨论其在降低建模门槛、固化专家经验以及推动自动化优化建模方面的潜力与当前局限。

## 相关链接

- [OptiMUS项目安装教程](https://github.com/teshnizi/OptiMUS?tab=readme-ov-file#optimus-optimization-modeling-using-mip-solvers-and-large-language-models) —— 官方使用与安装说明  
- [OptiMUS Live demo项目](https://optimus-solver.com/) —— OptiMUS求解器地址  
- [OptiMUS 原始论文](https://arxiv.org/abs/2407.19633) —— 《OptiMUS-0.3: Using large language models to model and solve optimization problems at scale》

## 思考

通过实验与对项目运行结果的分析，我们对Optimus的执行流程以及功能有了更深入的了解。

- 通过梳理 OptiMUS-0.3 的整体流程，可以更直观地认识到“大模型 + 传统求解器”的分工：LLM 更适合做需求理解、约束抽取与代码生成，而数学求解则仍依赖成熟的 (MI)LP 求解器，这种协同有望显著降低优化建模的使用门槛。
- 状态管理与误差修正模块提醒我们，大模型并非“万能建模师”，必须用结构化 JSON 状态、反射式提示、自评打分等机制持续约束和校正它的输出，否则幻觉和不一致会在复杂建模任务中被快速放大。
- 在大规模问题场景下，效率优化模块展示了工程化设计的重要性：例如结构检测、分块建模、高级编码策略等，都在尝试把人类专家的经验固化为可复用的自动化流程，而不仅仅是一次性调用 LLM 生成代码。
- 整体来看，LLM 辅助求解器为“从自然语言到可执行优化模型”提供了一个有前景的范式，但在约束严谨性、可解释性、安全性以及工业级规模上的稳定性等方面仍有不少挑战，需要后续继续探索与改进。